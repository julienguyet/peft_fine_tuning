# LLM Fine-tuning using PEFT

---

## 1. Introduction :open_book:

With this project we will see how you can fine-tune some parameters of your Large Language Model without having to retrain the whole model (which would be very long and very costly). 

If you wish to reuse this code and adapt it to your needs, I highly encourage you to use a Google Colab notebook with below parameters. Otherwise, you may have trouble loading and saving the model (250M parameters is quite heavy for a *standard* laptop).

<img width="549" alt="Screenshot 2024-06-10 at 18 19 32" src="https://github.com/julienguyet/peft_fine_tuning/assets/55974674/4d170554-a8ef-41b2-8953-cb0399f07487">

---

## 2. Loading the model :telescope:


