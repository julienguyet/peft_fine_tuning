{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fb6c82a871a34e089fb2ba471357985e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f742c0657a44d80b0eca1e686fe1a12",
              "IPY_MODEL_8049f399414a4085946aae31d0e68914",
              "IPY_MODEL_7dc918a4a1924fd19c7a5f13d66a8fba"
            ],
            "layout": "IPY_MODEL_63557b9adee54fee9cdbdbd53011b6c7"
          }
        },
        "0f742c0657a44d80b0eca1e686fe1a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7afe2396ff7148ce93974bf982be0b16",
            "placeholder": "​",
            "style": "IPY_MODEL_2ca8e35f3e6a4fda9cdea5fbcb01906e",
            "value": "Map: 100%"
          }
        },
        "8049f399414a4085946aae31d0e68914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17949a36554483bb788f7dbebc414b9",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13cd9503bf7740809eb92db90a87c8da",
            "value": 12460
          }
        },
        "7dc918a4a1924fd19c7a5f13d66a8fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0144ff5cb2b4badb4c79b44c7e3e850",
            "placeholder": "​",
            "style": "IPY_MODEL_d82bb079f0854038a6fbc0803d00709d",
            "value": " 12460/12460 [00:13&lt;00:00, 1256.66 examples/s]"
          }
        },
        "63557b9adee54fee9cdbdbd53011b6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7afe2396ff7148ce93974bf982be0b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ca8e35f3e6a4fda9cdea5fbcb01906e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f17949a36554483bb788f7dbebc414b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13cd9503bf7740809eb92db90a87c8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0144ff5cb2b4badb4c79b44c7e3e850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82bb079f0854038a6fbc0803d00709d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dbfb28cc90e47f8a538248cf8f5e791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27106d3f67e49b492d9825cd8e6dbed",
              "IPY_MODEL_09291137731b486e92b300d33d52a0d6",
              "IPY_MODEL_4e7b4543976b405ca6bb9512a9fd7be1"
            ],
            "layout": "IPY_MODEL_461d73c6560b4a9daa601ee5dfbb2a3e"
          }
        },
        "e27106d3f67e49b492d9825cd8e6dbed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_284fffa3d6bb4d50aab4520854eb0554",
            "placeholder": "​",
            "style": "IPY_MODEL_d87d0cbf1dff496eb2710b2f86b144e6",
            "value": "Map: 100%"
          }
        },
        "09291137731b486e92b300d33d52a0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_361e25d6dc4f45fbb80b8779a7e513b9",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49cacbc30c8d43f6b7a95fe1a4f0fbf0",
            "value": 500
          }
        },
        "4e7b4543976b405ca6bb9512a9fd7be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cde5d0fe3aa4d27ab154c8a65525bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ee6b011a6f54f3998e92eff6a149423",
            "value": " 500/500 [00:00&lt;00:00, 1731.97 examples/s]"
          }
        },
        "461d73c6560b4a9daa601ee5dfbb2a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "284fffa3d6bb4d50aab4520854eb0554": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d87d0cbf1dff496eb2710b2f86b144e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "361e25d6dc4f45fbb80b8779a7e513b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49cacbc30c8d43f6b7a95fe1a4f0fbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cde5d0fe3aa4d27ab154c8a65525bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ee6b011a6f54f3998e92eff6a149423": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b95b0bd58e14a5b901ca8fca1a77271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56a687eee38340c788b4ad6cbd228ccf",
              "IPY_MODEL_49506e50d1df48b783cbb0d820b952a7",
              "IPY_MODEL_4808776d28fd416495d8299edcbd17ef"
            ],
            "layout": "IPY_MODEL_7637d46f5e5347ec9872700a74a7237c"
          }
        },
        "56a687eee38340c788b4ad6cbd228ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a20e3b58bc4b81a716ae21eab11f69",
            "placeholder": "​",
            "style": "IPY_MODEL_ee17c1761e9940c7a34f940b4f83f907",
            "value": "Map: 100%"
          }
        },
        "49506e50d1df48b783cbb0d820b952a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46fd7dc08a7546179648405b5f318870",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ea33b5f9ca6476d99b118c9d7e68f0a",
            "value": 1500
          }
        },
        "4808776d28fd416495d8299edcbd17ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fafd906850cd4a799d4fa5e8718c5ea2",
            "placeholder": "​",
            "style": "IPY_MODEL_7a890bc06eef4bf79df72f7c25814f1f",
            "value": " 1500/1500 [00:00&lt;00:00, 1901.15 examples/s]"
          }
        },
        "7637d46f5e5347ec9872700a74a7237c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86a20e3b58bc4b81a716ae21eab11f69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee17c1761e9940c7a34f940b4f83f907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46fd7dc08a7546179648405b5f318870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea33b5f9ca6476d99b118c9d7e68f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fafd906850cd4a799d4fa5e8718c5ea2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a890bc06eef4bf79df72f7c25814f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "gLNkE1036Dlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This first section will install required dependencies."
      ],
      "metadata": {
        "id": "s8sPdIU8CUxd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-UkHaeC5OQN",
        "outputId": "ba0b406f-044b-46c5-ce3a-20e44a39a294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets peft torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGMBnRNI5wWf",
        "outputId": "6e33afad-b9f9-4aa0-bc01-0f9f1f7f8f6d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.25.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.23.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB6xSxyV_Rxe",
        "outputId": "a075dbe0-2668-41df-94a6-675ecd5908a2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Dataset\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "nzlbKw5u6KFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will work with the famous \"dialogsum\" dataset. It is made of dialogues that could happend between humans. All conversations have corresponding summaries.\n",
        "\n",
        "You can obtain more information [here](https://huggingface.co/datasets/knkarthick/dialogsum)."
      ],
      "metadata": {
        "id": "fcn_2rq8Cc9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig, TrainingArguments, Trainer\n",
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YM4giD9D5XDb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
        "\n",
        "dataset = load_dataset(huggingface_dataset_name)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYCwWOQc5kNT",
        "outputId": "7bd196b5-c802-4650-9f27-42ea994c4b31"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 12460\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'dialogue', 'summary', 'topic'],\n",
              "        num_rows: 1500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the dataset is coming with everything we need: train, validation and test sets. With more than 12k training conversations, we have everything we need for fine-tuning our LLM.\n",
        "\n",
        "Below is an example of the first dialogue and its corresponding summary:"
      ],
      "metadata": {
        "id": "6oxKJRzJDWcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"This is the dialogue:\\n{dataset['train'][0]['dialogue']}\")\n",
        "print(\"---\"*20)\n",
        "print(f\"This is the summary:\\n{dataset['train'][0]['summary']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2cvA0t655To",
        "outputId": "85234872-0dd4-49b5-c2f1-4b4ff1ab1851"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the dialogue:\n",
            "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
            "#Person2#: I found it would be a good idea to get a check-up.\n",
            "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
            "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
            "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
            "#Person2#: Ok.\n",
            "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
            "#Person2#: Yes.\n",
            "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
            "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
            "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
            "#Person2#: Ok, thanks doctor.\n",
            "------------------------------------------------------------\n",
            "This is the summary:\n",
            "Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is important to note that all summaries are human generated and will be our base for performance review of our model.\n",
        "Also, we should keep in mind that language is a complex topic, and of course we can never assure summaries are one hundred percent perfect."
      ],
      "metadata": {
        "id": "fUFzcOKPEdk2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing base Flan-T5"
      ],
      "metadata": {
        "id": "KUAJ9-Cf6N9W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start, we will load the Flan-T5 model designed by Google's team and first released in the paper *Scaling Instruction-Finetuned Language Models* (by HW Chung et al., 2022). Paper is available [here](https://arxiv.org/pdf/2210.11416) and you can consult module's documentation at HuggingFace dedicated [page](https://huggingface.co/docs/transformers/en/model_doc/flan-t5)."
      ],
      "metadata": {
        "id": "0CoNIWyUE4bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name='google/flan-t5-base'\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "sC3y7vlt58_O"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Out of curiosity, we will print below the number of parameters Flan-T5 is including. As you will see, numbers are quite outstanding with more than 200M parameters."
      ],
      "metadata": {
        "id": "aQtyN93vFyGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def original_model_parameters(model):\n",
        "    trainable_model_params = 0\n",
        "    all_model_params = 0\n",
        "\n",
        "    for layer, param in model.named_parameters():\n",
        "        all_model_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_model_params += param.numel()\n",
        "\n",
        "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
        "\n",
        "print(original_model_parameters(original_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6_9mC3V5-un",
        "outputId": "64ba2e58-f1a7-49c7-dcb2-144c6164d3ce"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable model parameters: 247577856\n",
            "all model parameters: 247577856\n",
            "percentage of trainable model parameters: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though all parameters are trainable, it is obvious that training from scratch such a model is impossible for simple individuals like us. However, we will see later how to still effectively \"retrain\" the model to suit our needs.\n",
        "\n",
        "For now, let's test Flan-T5 on our dataset and ask for summaries of dialogues."
      ],
      "metadata": {
        "id": "-4dITnkuGXgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = np.random.randint(100)\n",
        "\n",
        "dialogue = dataset[\"train\"][index][\"dialogue\"]\n",
        "summary = dataset[\"train\"][index][\"summary\"]\n",
        "\n",
        "print(f\"This is the dialogue at index {index}:\\n{dialogue}\")\n",
        "print(\"----\"*15)\n",
        "print(f\"This is the corresponding summary:\\n{summary}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDBhcR1c6Avx",
        "outputId": "f258e5d1-4138-44bf-a1a8-3bbe723d3557"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the dialogue at index 51:\n",
            "#Person1#: What kind of job do you intend to do?\n",
            "#Person2#: I want to do some management job since I have three-year's work history.\n",
            "#Person1#: What are your plans if you were hired?\n",
            "#Person2#: I would apply my specialty and experience to my job and gradually move up to the management level in this company.\n",
            "------------------------------------------------------------\n",
            "This is the corresponding summary:\n",
            "#Person2# tells #Person1# #Person2#'s ideal job and the job plan if hired.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we need to design a prompt template. We will use zero-shot inference, i.e. we will not provide any example of what we expect to the model. Feel free to compare performances by using one-shot or even few-shot inferences."
      ],
      "metadata": {
        "id": "kM2nEK-IHMwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "\n",
        "Summarize the following conversation:\n",
        "{dialogue}\n",
        "\n",
        "Summary:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WXmVV2sW6CaV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our prompt, we must:\n",
        "\n",
        "1.   Tokenize the input using a transformer architecture so the model can understand what we are asking (see [*Attention Is All You Need*](https://arxiv.org/abs/1706.03762) (by A Vaswani et al., 2017) for more details on how transformers work.\n",
        "2.   Decode the output so **we** can read it.\n",
        "\n"
      ],
      "metadata": {
        "id": "hdlOuvf7HmZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = tokenizer(prompt, return_tensors=\"pt\")\n",
        "output = tokenizer.decode(original_model.generate(input[\"input_ids\"],\n",
        "                                                max_new_tokens=200)[0],\n",
        "                                                skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "3eYefB2h6UNA"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok now that we have our prediction, let's compare it to the actual summary:"
      ],
      "metadata": {
        "id": "TwYxq1ckIcP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input Prompt:\\n{prompt}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"Baseline Human Summary:\\n{summary}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"LLM Summary - Zero Shot:\\n{output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkNvMiVk6Vrh",
        "outputId": "16a74628-9ec3-424a-f6da-5afbd25a7be1"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Prompt:\n",
            "\n",
            "\n",
            "Summarize the following conversation:\n",
            "#Person1#: What kind of job do you intend to do?\n",
            "#Person2#: I want to do some management job since I have three-year's work history.\n",
            "#Person1#: What are your plans if you were hired?\n",
            "#Person2#: I would apply my specialty and experience to my job and gradually move up to the management level in this company. \n",
            "\n",
            "Summary:\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Baseline Human Summary:\n",
            "#Person2# tells #Person1# #Person2#'s ideal job and the job plan if hired.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "LLM Summary - Zero Shot:\n",
            "Ask the person to describe their career goals.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are your thoughts on this? It looks like the model is very straight to the point, and lacking details in its summary. It is like the summary is too short and missing some valuable informations.\n",
        "\n",
        "To get an idea of the model performance, we will compute its ROUGE score. This score is calculated as below (higher the better):"
      ],
      "metadata": {
        "id": "Un-dG-idIiE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\text{ROUGE-1} = \\frac{\\text{Unigram Matches}}{\\text{Total number of unigram in reference}} $$\n"
      ],
      "metadata": {
        "id": "ak_33yGjI5eW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$$ \\text{ROUGE-2} = \\frac{\\text{Unigram Matches}}{\\text{Unigrams in Output}} $$"
      ],
      "metadata": {
        "id": "OPT-F93wLFFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\text{ROUGE-L} = \\frac{\\text{Length of longest common subsequence}}{\\text{Total number of words in reference summaries}} $$"
      ],
      "metadata": {
        "id": "tMckP6OjLJ-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "$$ \\text{ROUGE-Lsum} = \\frac{\\text{Total length of overlapping summary}}{\\text{Total length of reference summaries}} $$"
      ],
      "metadata": {
        "id": "2UKw8gUJLMe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=output,\n",
        "    references=summary[0:len(output)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQfFS2AS6XWd",
        "outputId": "fe7e74a7-ab5d-45a8-eed9-38d0fcdb4f1d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.021739130434782608, 'rouge2': 0.0, 'rougeL': 0.021739130434782608, 'rougeLsum': 0.021739130434782608}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clearly, our model is not performing especially well: even though Flan-T5 was designed to solve various tasks, it is not necessarly especially well designed to produced summaries on the go. Let's see how we can improve its performance."
      ],
      "metadata": {
        "id": "bEG4ryXCLP4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Parameter Efficient Fine-Tuning (PEFT)"
      ],
      "metadata": {
        "id": "d_RUHeeU63pu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will implement Parameter Efficient Fine-Tuning (or PEFT).\n",
        "\n",
        "Full fine-tuning of large LLMs are challenging and very costly, which makes it hard to retrain a whole model. With PEFT, the idea is to freeze most of the layers of our model, and update only some of the layers. Various methods exist to do this such as (i) \"Selective\" (only fine-tune some parameters), (ii) \"Reparameterization\" (implement a low rank representation of the model), or (iii) \"Additive\" (add trainable layers or parameters to the model).\n",
        "\n",
        "In this section we will go with the second option and use the [LoRA method](https://huggingface.co/docs/diffusers/main/en/training/lora)."
      ],
      "metadata": {
        "id": "LcP7A3zILugk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32,  # Rank of the submatrices\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM\n",
        ")\n",
        "\n",
        "model_name = 'google/flan-t5-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# we create the PEFT model\n",
        "peft_model = get_peft_model(original_model, lora_config)\n",
        "\n",
        "# we define an output directory for the trained model - this is key as we will save the model to be able to reuse it later\n",
        "output_dir = f'./peft-dialogue-summary-training-{str(int(time.time()))}'\n"
      ],
      "metadata": {
        "id": "EgvxhX2L6c6s"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we need to preprocess the dataset to correspond to LoRA expecations.\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples['dialogue']\n",
        "    targets = examples['summary']\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=128, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "fb6c82a871a34e089fb2ba471357985e",
            "0f742c0657a44d80b0eca1e686fe1a12",
            "8049f399414a4085946aae31d0e68914",
            "7dc918a4a1924fd19c7a5f13d66a8fba",
            "63557b9adee54fee9cdbdbd53011b6c7",
            "7afe2396ff7148ce93974bf982be0b16",
            "2ca8e35f3e6a4fda9cdea5fbcb01906e",
            "f17949a36554483bb788f7dbebc414b9",
            "13cd9503bf7740809eb92db90a87c8da",
            "f0144ff5cb2b4badb4c79b44c7e3e850",
            "d82bb079f0854038a6fbc0803d00709d",
            "3dbfb28cc90e47f8a538248cf8f5e791",
            "e27106d3f67e49b492d9825cd8e6dbed",
            "09291137731b486e92b300d33d52a0d6",
            "4e7b4543976b405ca6bb9512a9fd7be1",
            "461d73c6560b4a9daa601ee5dfbb2a3e",
            "284fffa3d6bb4d50aab4520854eb0554",
            "d87d0cbf1dff496eb2710b2f86b144e6",
            "361e25d6dc4f45fbb80b8779a7e513b9",
            "49cacbc30c8d43f6b7a95fe1a4f0fbf0",
            "4cde5d0fe3aa4d27ab154c8a65525bd3",
            "9ee6b011a6f54f3998e92eff6a149423",
            "6b95b0bd58e14a5b901ca8fca1a77271",
            "56a687eee38340c788b4ad6cbd228ccf",
            "49506e50d1df48b783cbb0d820b952a7",
            "4808776d28fd416495d8299edcbd17ef",
            "7637d46f5e5347ec9872700a74a7237c",
            "86a20e3b58bc4b81a716ae21eab11f69",
            "ee17c1761e9940c7a34f940b4f83f907",
            "46fd7dc08a7546179648405b5f318870",
            "7ea33b5f9ca6476d99b118c9d7e68f0a",
            "fafd906850cd4a799d4fa5e8718c5ea2",
            "7a890bc06eef4bf79df72f7c25814f1f"
          ]
        },
        "id": "oa2Qtcf4_dgM",
        "outputId": "5ff3878b-78cd-47e5-c8e2-1db9b5475f42"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb6c82a871a34e089fb2ba471357985e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dbfb28cc90e47f8a538248cf8f5e791"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b95b0bd58e14a5b901ca8fca1a77271"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator for padding\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=original_model)"
      ],
      "metadata": {
        "id": "uGtkkGKJ74ci"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can design our training. Note that we minimized most of the options here in the sake of computation time. Feel free to play with these parameters to see how performance of the model changes."
      ],
      "metadata": {
        "id": "ItryZYraNbhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peft_training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    auto_find_batch_size=True,\n",
        "    learning_rate=1e-3,\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=10,\n",
        "    max_steps=100,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=10,\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSOi35Ya7MvR",
        "outputId": "aca67a90-8a47-48ec-a213-9b1551f4c1c4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we train our new model\n",
        "peft_trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "JmagtSgV8FcK",
        "outputId": "3fb70013-b967-426f-e3ec-e9e833d7e4cf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 04:29, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.686600</td>\n",
              "      <td>1.302095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.430300</td>\n",
              "      <td>1.228671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.514600</td>\n",
              "      <td>1.197252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.406900</td>\n",
              "      <td>1.194839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.301500</td>\n",
              "      <td>1.178031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.413400</td>\n",
              "      <td>1.172116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.314400</td>\n",
              "      <td>1.165537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.177300</td>\n",
              "      <td>1.159838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.298200</td>\n",
              "      <td>1.159395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.319900</td>\n",
              "      <td>1.159831</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.3863263034820557, metrics={'train_runtime': 270.7186, 'train_samples_per_second': 2.955, 'train_steps_per_second': 0.369, 'total_flos': 409095060406272.0, 'train_loss': 1.3863263034820557, 'epoch': 0.06418485237483953})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we save the fine-tuned model and its tokenizer for later use\n",
        "peft_model_path = \"./peft-dialogue-summary-checkpoint-local\"\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB5lOkU0OGxb",
        "outputId": "6dc72267-d909-4c6f-ecdc-704db6fec4c0"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./peft-dialogue-summary-checkpoint-local/tokenizer_config.json',\n",
              " './peft-dialogue-summary-checkpoint-local/special_tokens_map.json',\n",
              " './peft-dialogue-summary-checkpoint-local/spiece.model',\n",
              " './peft-dialogue-summary-checkpoint-local/added_tokens.json',\n",
              " './peft-dialogue-summary-checkpoint-local/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device to GPU (or CPU if GPU is not available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Clearing any existing cache (if applicable) in case we run the code a multiple times and RAM is full\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(peft_model_path)\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base').to(device)\n",
        "fine_tuned_model = PeftModel.from_pretrained(original_model, peft_model_path).to(device)\n"
      ],
      "metadata": {
        "id": "ye2G6HpC79fs"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).input_ids.to(device)\n",
        "\n",
        "output_PEFT = tokenizer.decode(fine_tuned_model.model.generate(input_ids, max_new_tokens=100)[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "MbxcTrLK-N25"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok now, let's see what are our outputs:"
      ],
      "metadata": {
        "id": "i2XLDARjOkcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input Prompt:\\n{prompt}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"Baseline Human Summary:\\n{summary}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"Base Model Summary - Zero Shot:\\n{output}\")\n",
        "print(\"-----\"*20)\n",
        "print(f\"PEFT Model Summary - Zero Shot:\\n{output_PEFT}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBUKSrw8_qSK",
        "outputId": "a4206f7a-2fd1-42f4-c560-7f39308f3bd5"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Prompt:\n",
            "\n",
            "\n",
            "Summarize the following conversation:\n",
            "#Person1#: What kind of job do you intend to do?\n",
            "#Person2#: I want to do some management job since I have three-year's work history.\n",
            "#Person1#: What are your plans if you were hired?\n",
            "#Person2#: I would apply my specialty and experience to my job and gradually move up to the management level in this company. \n",
            "\n",
            "Summary:\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Baseline Human Summary:\n",
            "#Person2# tells #Person1# #Person2#'s ideal job and the job plan if hired.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Base Model Summary - Zero Shot:\n",
            "Ask the person to describe their career goals.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "PEFT Model Summary - Zero Shot:\n",
            "#Person2# wants to do some management job because he has three years' work history.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It seems our PEFT model is performing slightly better than the base model thanks to our training. However, compared to the human summary, we could argue that the difference is still obvious.\n",
        "\n",
        "Let's score our model and compare performances with the base:"
      ],
      "metadata": {
        "id": "RcPPJYGTOiX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "if len(output_PEFT) > len(summary):\n",
        "    output_PEFT = output_PEFT[:len(summary)]\n",
        "else:\n",
        "    summary = summary[:len(output_PEFT)]\n",
        "\n",
        "PEFT_model_results = rouge.compute(\n",
        "    predictions=output_PEFT,\n",
        "    references=summary,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print(\"----\"*20)\n",
        "print(\"PEFT MODEL:\")\n",
        "print(PEFT_model_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek2GlswB-L-u",
        "outputId": "b1a23aad-7232-42de-8578-1088eec8230e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': 0.021739130434782608, 'rouge2': 0.0, 'rougeL': 0.021739130434782608, 'rougeLsum': 0.021739130434782608}\n",
            "--------------------------------------------------------------------------------\n",
            "PEFT MODEL:\n",
            "{'rouge1': 0.12162162162162163, 'rouge2': 0.0, 'rougeL': 0.12162162162162163, 'rougeLsum': 0.12162162162162163}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numbers do the talking here: even if not perfect, our PEFT model is surclassing the base by far. This proves that with good parameters and enough training, PEFT can provide real good improvements and help us to design an LLM better suited to our use case."
      ],
      "metadata": {
        "id": "ShgHv9ooPQps"
      }
    }
  ]
}